"use strict";(self.webpackChunkrunn2011blog=self.webpackChunkrunn2011blog||[]).push([[9347],{3958:(e,t,r)=>{r.r(t),r.d(t,{comp:()=>o,data:()=>i});var n=r(641);const a=r.p+"assets/img/梯度下降.89d2f7c8.png",p=r.p+"assets/img/梯度下降1.7a317ffd.png",s={},o=(0,r(6262).A)(s,[["render",function(e,t){return(0,n.uX)(),(0,n.CE)("div",null,t[0]||(t[0]=[(0,n.Fv)('<h1 id="线性回归" tabindex="-1"><a class="header-anchor" href="#线性回归"><span>线性回归</span></a></h1><p>线性回归是一种基础监督学习算法，机器学习最基础的学习算法之一。</p><p>一般最基础的使用<strong>损失函数</strong>和<strong>梯度下降算法</strong></p><p>下面给老太太讲什么是线性回归。</p><hr><h2 id="📖-什么是线性回归" tabindex="-1"><a class="header-anchor" href="#📖-什么是线性回归"><span>📖 什么是线性回归？</span></a></h2><p>想象你有个小孙子，每天吃多少饭（米饭的重量）和他的体重有关系。你记录了他这几天吃饭和体重的情况，想找出<strong>吃饭量和体重之间的关系</strong>。</p><p>我们可以画个图，横着是「吃饭量」，竖着是「体重」，然后在图上把这些天的记录点点画出来。</p><p><strong>线性回归</strong>就是：<br> 👉 找一条<strong>直线</strong>，大致穿过这些点，表示吃饭量和体重的关系。</p><hr><h2 id="📖-为什么要用「损失函数」mse" tabindex="-1"><a class="header-anchor" href="#📖-为什么要用「损失函数」mse"><span>📖 为什么要用「损失函数」MSE？</span></a></h2><p>你肯定想问：“我随便画条线也行啊，为什么还要计算什么损失？”</p><p>因为：</p><ul><li>有的直线画得好，离这些点点都很近；</li><li>有的直线画得差，离点点很远。</li></ul><p>我们需要一个办法来<strong>衡量每条线画得好不好</strong>。</p><p>👉 损失函数就是用来「算一算这条线画得好不好」的。</p><h3 id="📌-什么是-mse" tabindex="-1"><a class="header-anchor" href="#📌-什么是-mse"><span>📌 什么是 MSE？</span></a></h3><p>MSE 全名叫<strong>均方误差（Mean Squared Error）</strong>，别怕名字，意思就是：</p><ol><li>每个点到这条直线的“竖直距离”，算一下是多少（叫误差）；</li><li>把这些距离平方（不管是正是负，都变成正数）；</li><li>再把所有平方值加起来，算个平均数。</li></ol><p>👉 数字越小，说明这条线画得越好。</p><p>就好比你每天织毛衣，看看针脚是不是整齐，越整齐，分数越高。</p><hr><h2 id="📖-为什么用「梯度下降法」来找最好的线" tabindex="-1"><a class="header-anchor" href="#📖-为什么用「梯度下降法」来找最好的线"><span>📖 为什么用「梯度下降法」来找最好的线？</span></a></h2><p>你现在知道要找条线，得让 MSE 尽量小。</p><p>问题是，可能有无数条线，怎么找呢？总不能把所有线都画一遍，比一比吧，太累了。</p><p>👉 所以我们用「梯度下降法」来帮忙。</p><h3 id="📌-什么是梯度下降法" tabindex="-1"><a class="header-anchor" href="#📌-什么是梯度下降法"><span>📌 什么是梯度下降法？</span></a></h3><p>假设你现在站在山上（代表 MSE 很高），你想找到山谷里最低的那个点（代表 MSE 最小，也就是最佳的那条线）。</p><p>你怎么办？</p><ul><li>每次顺着最陡的方向走几步（这叫求梯度，就是看看哪边坡最陡）；</li><li>一直走到坡度不再变，到了最低处。</li></ul><p>这就叫「梯度下降法」。</p><hr><h2 id="📖-总结给老太太听-🌸" tabindex="-1"><a class="header-anchor" href="#📖-总结给老太太听-🌸"><span>📖 总结给老太太听 🌸</span></a></h2><ul><li><strong>线性回归</strong>是找一条直线，描述「吃多少饭和体重」之间的关系。</li><li>**损失函数（MSE）**是量尺，看看你画的这条线和所有点点距离有多大，越小越好。</li><li><strong>梯度下降法</strong>是帮你找到最好的那条线，不用乱试，顺着最陡的坡，一步步走到最低处。</li></ul><p>就像做饭：</p><ul><li>你要调味（线性回归）；</li><li>尝一口看看咸淡（损失函数）；</li><li>一点点加盐（梯度下降法），直到刚刚好。</li></ul><hr><h2 id="梯度下降算法是怎么回事" tabindex="-1"><a class="header-anchor" href="#梯度下降算法是怎么回事"><span>梯度下降算法是怎么回事</span></a></h2><p>我们把上面的函数写作<br><strong>Z=kX+b</strong><br> Z是关于k,b的二元函数，可以画作：</p><p><img src="'+a+'" alt="" loading="lazy"><br><a href="https://www.bilibili.com/video/BV19f421Q7CL/?spm_id_from=333.337.search-card.all.click&amp;vd_source=9f4e814662b4f1f152382d2489347ba9" target="_blank" rel="noopener noreferrer">B站-有趣的理工男</a></p><p>通过分别对二元函数求b和k的偏导，得到<strong>梯度向量{df/dk, df/db}</strong>， 当梯度为0时的k,b就是最小损失函数值时的，线性回归的k，b值<br><img src="'+p+'" alt="" loading="lazy"></p><h2 id="reference" tabindex="-1"><a class="header-anchor" href="#reference"><span>Reference</span></a></h2><p><a href="https://www.bilibili.com/video/BV19f421Q7CL/?spm_id_from=333.337.search-card.all.click&amp;vd_source=9f4e814662b4f1f152382d2489347ba9" target="_blank" rel="noopener noreferrer">B站-有趣的理工男</a></p>',43)]))}]]),i=JSON.parse('{"path":"/posts/Math/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.html","title":"线性回归","lang":"zh-CN","frontmatter":{"date":"2025-07-06T00:00:00.000Z","tag":["Math","AI_GEN"],"description":"线性回归 线性回归是一种基础监督学习算法，机器学习最基础的学习算法之一。 一般最基础的使用损失函数和梯度下降算法 下面给老太太讲什么是线性回归。 📖 什么是线性回归？ 想象你有个小孙子，每天吃多少饭（米饭的重量）和他的体重有关系。你记录了他这几天吃饭和体重的情况，想找出吃饭量和体重之间的关系。 我们可以画个图，横着是「吃饭量」，竖着是「体重」，然后在...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"线性回归\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-07-06T00:00:00.000Z\\",\\"dateModified\\":\\"2025-07-06T11:06:44.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Runner2011\\",\\"url\\":\\"https://runner2011.github.io\\"}]}"],["meta",{"property":"og:url","content":"https://runner2011.github.io/posts/Math/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.html"}],["meta",{"property":"og:site_name","content":"Runner2011 blog"}],["meta",{"property":"og:title","content":"线性回归"}],["meta",{"property":"og:description","content":"线性回归 线性回归是一种基础监督学习算法，机器学习最基础的学习算法之一。 一般最基础的使用损失函数和梯度下降算法 下面给老太太讲什么是线性回归。 📖 什么是线性回归？ 想象你有个小孙子，每天吃多少饭（米饭的重量）和他的体重有关系。你记录了他这几天吃饭和体重的情况，想找出吃饭量和体重之间的关系。 我们可以画个图，横着是「吃饭量」，竖着是「体重」，然后在..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-07-06T11:06:44.000Z"}],["meta",{"property":"article:tag","content":"AI_GEN"}],["meta",{"property":"article:tag","content":"Math"}],["meta",{"property":"article:published_time","content":"2025-07-06T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-07-06T11:06:44.000Z"}]]},"git":{"createdTime":1751800004000,"updatedTime":1751800004000,"contributors":[{"name":"Runner2011","username":"Runner2011","email":"chenjfsea@gmail.com","commits":1,"url":"https://github.com/Runner2011"}]},"readingTime":{"minutes":2.89,"words":866},"filePathRelative":"posts/Math/线性回归.md","excerpt":"\\n<p>线性回归是一种基础监督学习算法，机器学习最基础的学习算法之一。</p>\\n<p>一般最基础的使用<strong>损失函数</strong>和<strong>梯度下降算法</strong></p>\\n<p>下面给老太太讲什么是线性回归。</p>\\n<hr>\\n<h2>📖 什么是线性回归？</h2>\\n<p>想象你有个小孙子，每天吃多少饭（米饭的重量）和他的体重有关系。你记录了他这几天吃饭和体重的情况，想找出<strong>吃饭量和体重之间的关系</strong>。</p>\\n<p>我们可以画个图，横着是「吃饭量」，竖着是「体重」，然后在图上把这些天的记录点点画出来。</p>\\n<p><strong>线性回归</strong>就是：<br>\\n👉 找一条<strong>直线</strong>，大致穿过这些点，表示吃饭量和体重的关系。</p>","autoDesc":true}')},6262:(e,t)=>{t.A=(e,t)=>{const r=e.__vccOpts||e;for(const[e,n]of t)r[e]=n;return r}}}]);